import os
import glob
import time
from ultralytics import YOLO
import cv2
import shutil

# ================= é…ç½®åŒºåŸŸ =================
# é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
# æ•°æ®é›†é…ç½®æ–‡ä»¶
DATA_YAML = os.path.join(BASE_DIR, "datasets", "power_inspection", "data.yaml")
# ç»“æœä¿å­˜æ ¹ç›®å½•
RUNS_DIR = os.path.join(BASE_DIR, "runs", "detect")
# æƒé‡æ–‡ä»¶å­˜æ”¾ç›®å½•
WEIGHTS_DIR = os.path.join(BASE_DIR, "weights")

# è®­ç»ƒå‚æ•°
MODEL_TYPE = os.path.join(WEIGHTS_DIR, "yolo11n.pt")
EPOCHS = 50
BATCH_SIZE = 16
IMG_SIZE = 640
DEVICE = 0


# ===========================================

def get_all_trained_models():
    """
    æ‰«æ runs/detect ä¸‹æ‰€æœ‰åŒ…å« weights/best.pt çš„æ–‡ä»¶å¤¹
    è¿”å›åˆ—è¡¨: [{'name': 'train4', 'path': '...', 'time': '...'}, ...]
    """
    if not os.path.exists(RUNS_DIR):
        return []

    # æ‰¾æ‰€æœ‰ train å¼€å¤´çš„æ–‡ä»¶å¤¹
    candidates = [d for d in os.listdir(RUNS_DIR) if d.startswith('train') and os.path.isdir(os.path.join(RUNS_DIR, d))]

    valid_models = []
    for folder in candidates:
        pt_path = os.path.join(RUNS_DIR, folder, "weights", "best.pt")
        if os.path.exists(pt_path):
            # è·å–æœ€åä¿®æ”¹æ—¶é—´
            mtime = os.path.getmtime(pt_path)
            time_str = time.strftime('%Y-%m-%d %H:%M', time.localtime(mtime))
            valid_models.append({
                'name': folder,
                'path': pt_path,
                'mtime': mtime,
                'time_str': time_str
            })

    # æŒ‰æ—¶é—´å€’åºæ’åˆ— (æœ€æ–°çš„åœ¨å‰)
    valid_models.sort(key=lambda x: x['mtime'], reverse=True)
    return valid_models


def select_model_interactive():
    """
    äº¤äº’å¼è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹
    """
    models = get_all_trained_models()

    if not models:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒå¥½çš„æ¨¡å‹ (best.pt)ã€‚è¯·å…ˆæ‰§è¡Œè®­ç»ƒã€‚")
        return None

    print("\n" + "=" * 50)
    print("ğŸ“‹ å¯ç”¨çš„è®­ç»ƒè®°å½•:")
    print("=" * 50)
    for i, m in enumerate(models):
        print(f" [{i + 1}] {m['name']:<10} | ğŸ•’ {m['time_str']} | ğŸ“‚ {m['path']}")
    print("=" * 50)

    while True:
        choice = input(f"è¯·è¾“å…¥åºå·é€‰æ‹©æ¨¡å‹ (1-{len(models)}, å›è½¦é»˜è®¤é€‰æœ€æ–°): ").strip()
        if choice == "":
            selected = models[0]
            break
        elif choice.isdigit():
            idx = int(choice) - 1
            if 0 <= idx < len(models):
                selected = models[idx]
                break
        print("è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

    print(f"\nâœ… å·²é”å®šæ¨¡å‹: {selected['name']} ({selected['path']})")
    return selected['path']


def train_model():
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {MODEL_TYPE} | Epochs: {EPOCHS}")
    model = YOLO(MODEL_TYPE)
    model.train(
        data=DATA_YAML,
        epochs=EPOCHS,
        imgsz=IMG_SIZE,
        batch=BATCH_SIZE,
        device=DEVICE,
        workers=2,
        project=RUNS_DIR,
        name="train"
    )
    print("âœ… è®­ç»ƒå®Œæˆï¼")


def evaluate_model():
    print("ğŸ“Š [è¯„ä¼°æ¨¡å¼]")
    model_path = select_model_interactive()
    if not model_path: return

    print("æ­£åœ¨åŠ è½½æ¨¡å‹è¿›è¡Œè¯„ä¼°...")
    model = YOLO(model_path)
    metrics = model.val(data=DATA_YAML, split='test', device=DEVICE)

    print(f"ğŸ“ˆ mAP50:    {metrics.box.map50:.4f}")
    print(f"ğŸ“ˆ mAP50-95: {metrics.box.map:.4f}")
    print(f"ğŸ“‚ è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {metrics.save_dir}")


def predict_single_image():
    print("ğŸ–¼ï¸ [æ¨ç†æ¨¡å¼]")
    model_path = select_model_interactive()
    if not model_path: return

    model = YOLO(model_path)

    img_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„ (æ”¯æŒæ‹–å…¥æ–‡ä»¶): ").strip().strip('"')
    if not os.path.exists(img_path):
        print("âŒ å›¾ç‰‡ä¸å­˜åœ¨ã€‚")
        return

    results = model.predict(img_path, save=True, conf=0.25)
    print(f"âœ… æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {results[0].save_dir}")

    try:
        res_plot = results[0].plot()
        cv2.imshow("Result", res_plot)
        print("æŒ‰ä»»æ„é”®å…³é—­çª—å£...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    except:
        pass


def export_to_onnx():
    """
    å°† .pt è½¬æ¢ä¸º .onnx (ä¸º TensorRT åšå‡†å¤‡)
    """
    print("ğŸ“¦ [æ¨¡å‹å¯¼å‡ºæ¨¡å¼ - ONNX]")
    print("æ­¤æ­¥éª¤ç”Ÿæˆçš„ .onnx æ–‡ä»¶å°†äº¤ç»™æˆå‘˜Cè¿›è¡Œ C++ TensorRT éƒ¨ç½²ã€‚")

    model_path = select_model_interactive()
    if not model_path: return

    print("\nâ³ æ­£åœ¨å¯¼å‡º ONNXï¼Œè¯·ç¨å€™...")
    model = YOLO(model_path)

    # æ ¸å¿ƒå¯¼å‡ºä»£ç 
    # dynamic=True: æ”¯æŒåŠ¨æ€è¾“å…¥å°ºå¯¸ and åŠ¨æ€Batch (TensorRT å…³é”®è¦æ±‚)
    # simplify=True: ä½¿ç”¨ onnxsim ç®€åŒ–å›¾ç»“æ„
    # opset=12: å…¼å®¹æ€§æœ€å¥½çš„ç®—å­é›†
    success = model.export(
        format='onnx',
        dynamic=True,
        simplify=True,
        opset=12
    )

    if success:
        onnx_path = model_path.replace('.pt', '.onnx')
        print("\n" + "*" * 50)
        print("ğŸ‰ å¯¼å‡ºæˆåŠŸï¼")
        print(f"ğŸ“‚ ONNX æ–‡ä»¶è·¯å¾„: {onnx_path}")
        print("*" * 50)
        print("ğŸ‘‰ ä¸‹ä¸€æ­¥: è¯·å°†æ­¤æ–‡ä»¶å‘é€ç»™æˆå‘˜Cï¼Œä»–å°†ä½¿ç”¨ TensorRT C++ API åŠ è½½å®ƒã€‚")
    else:
        print("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—ã€‚")


def main():
    while True:
        print("\n" + "=" * 30)
        print("   YOLOv11 ä»»åŠ¡ç®¡ç†å™¨ (v3.0 Pro)")
        print("=" * 30)
        print("1. [è®­ç»ƒ] æ–°ä¸€è½®è®­ç»ƒ (Train)")
        print("2. [è¯„ä¼°] è¯„ä¼°å†å²æ¨¡å‹ (Evaluate)")
        print("3. [æ¨ç†] å•å›¾æµ‹è¯• (Predict)")
        print("4. [å¯¼å‡º] è½¬ä¸º ONNX æ ¼å¼ (Export)")
        print("q. é€€å‡º")

        choice = input("è¯·é€‰æ‹©ä»»åŠ¡: ").lower()

        if choice == '1':
            train_model()
        elif choice == '2':
            evaluate_model()
        elif choice == '3':
            predict_single_image()
        elif choice == '4':
            export_to_onnx()
        elif choice == 'q':
            break


if __name__ == "__main__":
    main()
